---
title: "STSCI-4740 Final Project R Code"
date: "2023-12-01"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage 

## Data Processing:
```{r}
# Data Processing
set.seed(21)
WineDataDF <- as.data.frame(read.csv("wine-quality-white-and-red.csv", header = TRUE))
WineDataDF$type <- ifelse(WineDataDF$type == "white", 1, 0)
# Plot histograms data
p <- ncol(WineDataDF)
for (i in 1:p){
  hist(x = as.numeric(WineDataDF[,i]), xlab = names(WineDataDF)[i], main = paste("Histogram of", names(WineDataDF)[i], sep = " "))
}
table(WineDataDF$quality)
# To avoid QDA or Naive Bayes breaking down, we merge the smallest classes to the closest biggest class
WineDataDF$quality[WineDataDF$quality == 9] <- 8
WineDataDF$quality[WineDataDF$quality == 3] <- 4
table(WineDataDF$quality)

# A simple validation set approach will be used - split data to (~ 20%) test and (~ 80%) train
n <- nrow(WineDataDF)
train_index <- sample(1:n, size = round(0.8*n))
train_data <- WineDataDF[train_index, ]
test_data <- WineDataDF[-train_index, ]

# Analyze predictors & response correlation
library(corrplot)
train_corr <- cor(train_data)
train_corr
corrplot(train_corr, method = "number")
# find predictors correlated with quality
sort(abs(train_corr[,13]))

# change quality to factor variable
train_data$quality <- as.factor(train_data$quality)
test_data$quality <- as.factor(test_data$quality)
y <- test_data$quality

# PCA analysis
xtrain <- train_data[,-13]
pca.results <- princomp(xtrain, cor = TRUE)
summary(pca.results)
# Scree plot - helps in choosing predictors
screeplot(pca.results, type = "l", main = "Scree Plot for Principal Components")
abline(1,0,col='red', lty = 2)
pca.df <- as.data.frame(pca.results$scores)
pca.df$quality <- train_data$quality
# test PCs
xtest <- test_data[,-13]
test_pca.df <- as.data.frame(princomp(xtest, cor = TRUE)$scores)
```

\newpage

## Multinomial Logistic Regression Analysis:
```{r}
library(nnet)
set.seed(21)
mlr.fit <- multinom(quality ~ volatile.acidity + alcohol + chlorides + fixed.acidity + citric.acid + free.sulfur.dioxide, data = train_data, trace = FALSE)
summary(mlr.fit)
mlr_pred <- predict(mlr.fit, newdata = test_data)
mlr_test_error <- mean(y != mlr_pred)
mlr_test_error
pca_mlr.fit <- multinom(quality ~ Comp.1 + Comp.2 + Comp.3 + Comp.4, data = pca.df, trace = FALSE)
summary(pca_mlr.fit)
pca_mlr_pred <- predict(pca_mlr.fit, newdata = test_pca.df)
pca_mlr_test_error <- mean(y != pca_mlr_pred)
pca_mlr_test_error
```

\newpage

## Linear Discriminant Analysis, Quadratic Discriminant Analysis, and Naive Bayes Analyses:
```{r}
library(MASS)
library(e1071)
library(klaR)
options(warn = -1)
set.seed(21)
# LDA
lda.fit <- lda(quality ~ volatile.acidity + alcohol + chlorides + fixed.acidity + citric.acid + free.sulfur.dioxide, data = train_data)
lda_pred <- predict(lda.fit, newdata = test_data)
lda_test_error <- mean(y != lda_pred$class)
lda_test_error
pca_lda.fit <- lda(quality ~ Comp.1 + Comp.2 + Comp.3 + Comp.4, data = pca.df)
pca_lda_pred <- predict(pca_lda.fit, newdata = test_pca.df)
pca_lda_test_error <- mean(y != pca_lda_pred$class)
pca_lda_test_error

# QDA
qda.fit <- qda(quality ~ volatile.acidity + alcohol + chlorides + fixed.acidity + citric.acid + free.sulfur.dioxide, data = train_data)
qda_pred <- predict(qda.fit, newdata = test_data)
qda_test_error <- mean(y != qda_pred$class)
qda_test_error
pca_qda.fit <- qda(quality ~ Comp.1 + Comp.2 + Comp.3 + Comp.4, data = pca.df)
pca_qda_pred <- predict(pca_qda.fit, newdata = test_pca.df)
pca_qda_test_error <- mean(y != pca_qda_pred$class)
pca_qda_test_error

# Naive Bayes
nb.fit <- naiveBayes(quality ~ volatile.acidity + alcohol + chlorides + fixed.acidity + citric.acid + free.sulfur.dioxide, data = train_data)
nb_pred <- predict(nb.fit, newdata = test_data)
nb_test_error <- mean(y != nb_pred)
nb_test_error
knb.fit <- NaiveBayes(quality ~ volatile.acidity + alcohol + chlorides + fixed.acidity + citric.acid + free.sulfur.dioxide, data = train_data, usekernel = TRUE)
knb_pred <- predict(knb.fit, newdata = test_data)
knb_test_error <- mean(y != knb_pred$class)
knb_test_error
pca_nb.fit <- naiveBayes(quality ~ Comp.1 + Comp.2 + Comp.3 + Comp.4, data = pca.df)
pca_nb_pred <- predict(pca_nb.fit, newdata = test_pca.df)
pca_nb_test_error <- mean(y != pca_nb_pred)
pca_nb_test_error
kpca_nb.fit <- NaiveBayes(quality ~ Comp.1 + Comp.2 + Comp.3 + Comp.4, data = pca.df, usekernel = TRUE)
kpca_nb_pred <- predict(kpca_nb.fit, newdata = test_pca.df)
kpca_nb_test_error <- mean(y != kpca_nb_pred$class)
kpca_nb_test_error
```

\newpage

## KNN Analysis:
```{r}
library(class)
set.seed(21)
N <- 100
knn_test_errors <- rep(0, N)
knn_pca_test_errors <- rep(0, N)
Xtr <- as.data.frame(cbind(xtrain$volatile.acidity, xtrain$alcohol, xtrain$chlorides, xtrain$fixed.acidity, xtrain$citric.acid, xtrain$free.sulfur.dioxide))
Xte <- as.data.frame(cbind(xtest$volatile.acidity, xtest$alcohol, xtest$chlorides, xtest$fixed.acidity, xtest$citric.acid, xtest$free.sulfur.dioxide))
pcatrain <- pca.df[,1:4]
pcatest <- test_pca.df[,1:4]
for(i in 1:N){
  knn.pred <- knn(Xtr, Xte, train_data$quality, k = i) 
  knn_test_errors[i] <- mean(y != knn.pred)
  pca_knn.pred <- knn(pcatrain, pcatest, pca.df$quality, k = i)
  knn_pca_test_errors[i] <- mean(y != pca_knn.pred)
}
min(knn_test_errors)
k1 <- which(knn_test_errors == min(knn_test_errors))
k1
min(knn_pca_test_errors)
k2 <- which(knn_pca_test_errors == min(knn_pca_test_errors))
k2
```

\newpage

## Support Vector Machine Analysis:
```{r}
library(e1071)
set.seed(21)
# fit best model
lin_tune.out <- tune(svm , quality ~ volatile.acidity + alcohol + chlorides + fixed.acidity + citric.acid + free.sulfur.dioxide, data = train_data , kernel = "linear",
ranges = list(cost = c(0.001 , 0.01, 0.1, 1, 5, 10, 100)))
summary(lin_tune.out)
pca_lin_tune.out <- tune(svm , quality ~ Comp.1 + Comp.2 + Comp.3 + Comp.4, data = pca.df, kernel = "linear",
ranges = list(cost = c(0.001 , 0.01, 0.1, 1, 5, 10, 100)))
summary(pca_lin_tune.out)
rad_tune.out <- tune(svm , quality ~ volatile.acidity + alcohol + chlorides + fixed.acidity + citric.acid + free.sulfur.dioxide, data = train_data, kernel = "radial",ranges = list(cost = c(0.1 , 1, 10, 100, 1000) ,gamma = c(0.5, 1, 2, 3, 4)))
summary(rad_tune.out)
pca_rad_tune.out <- tune(svm , quality ~ Comp.1 + Comp.2 + Comp.3 + Comp.4, data = pca.df, kernel = "radial",ranges = list(cost = c(0.1 , 1, 10, 100, 1000) ,gamma = c(0.5, 1, 2, 3, 4)))
summary(pca_rad_tune.out)

# predictions
svml.pred <- predict(lin_tune.out$best.model, newdata=test_data)
svml_test_error <- mean(y != svml.pred)
svml_test_error
pca_svml.pred <- predict(pca_lin_tune.out$best.model, newdata= test_pca.df)
pca_svml_test_error <- mean(y != pca_svml.pred)
pca_svml_test_error
svmr.pred <- predict(rad_tune.out$best.model, newdata=test_data)
svmr_test_error <- mean(y != svmr.pred)
svmr_test_error
pca_svmr.pred <- predict(pca_rad_tune.out$best.model, newdata=test_pca.df)
pca_svmr_test_error <- mean(y != pca_svmr.pred)
pca_svmr_test_error
```